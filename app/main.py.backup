"""
Jarvis AI Backend - Multi-Agent Orchestrator API
FastAPI + WebSockets for real-time communication
Complete implementation with all required features
"""

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Query, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Set
import asyncio
import json
import uuid
from datetime import datetime
import logging
from enum import Enum
import redis.asyncio as redis
from contextlib import asynccontextmanager
import uvicorn

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Redis connection (optional, fallback to in-memory if not available)
redis_client = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifecycle"""
    global redis_client
    try:
        redis_client = await redis.from_url("redis://localhost:6379", decode_responses=True)
        await redis_client.ping()
        logger.info("Connected to Redis")
    except Exception as e:
        logger.warning(f"Redis not available, using in-memory storage: {e}")
        redis_client = None
    
    # Initialize sample data
    await initialize_sample_data()
    
    yield
    
    # Cleanup
    if redis_client:
        await redis_client.close()

# Create FastAPI app
app = FastAPI(
    title="Jarvis AI Orchestrator Backend",
    version="2.0.0",
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:1420", "http://localhost:5173", "http://127.0.0.1:1420", "tauri://localhost"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Enums
class TaskStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    DEAD_END = "dead_end"
    HITL_REQUIRED = "hitl_required"

class LogLevel(str, Enum):
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AgentRole(str, Enum):
    RESEARCHER = "researcher"
    ANALYST = "analyst"
    EXECUTOR = "executor"
    VALIDATOR = "validator"
    COORDINATOR = "coordinator"

# Data Models
class WorkflowNode(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    type: str
    position: Dict[str, float]
    data: Dict[str, Any]
    status: TaskStatus = TaskStatus.PENDING
    reasoning: Optional[str] = None
    tool_outputs: Optional[List[Dict[str, Any]]] = None
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())

class WorkflowEdge(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    source: str
    target: str
    type: str = "default"
    animated: bool = False
    label: Optional[str] = None

class Workflow(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str
    name: str
    nodes: List[WorkflowNode]
    edges: List[WorkflowEdge]
    status: TaskStatus = TaskStatus.PENDING
    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = {}

class LogEntry(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str
    agent_id: Optional[str] = None
    level: LogLevel
    message: str
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = {}

class HITLRequest(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    task_id: str
    session_id: str
    type: str  # "approval", "input", "decision"
    prompt: str
    options: Optional[List[str]] = None
    context: Dict[str, Any] = {}
    status: str = "pending"  # "pending", "approved", "denied", "timeout"
    response: Optional[Any] = None
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())

class DeadEndTask(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str
    task_id: str
    reason: str
    original_input: Dict[str, Any]
    attempted_solutions: List[str] = []
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())
    can_retry: bool = True

class Mission(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    description: str
    objectives: List[str]
    constraints: Optional[List[str]] = None
    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())

class Agent(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    role: AgentRole
    capabilities: List[str]
    status: str = "idle"
    current_task: Optional[str] = None

# In-memory storage
workflows_db: Dict[str, Workflow] = {}
logs_db: List[LogEntry] = []
hitl_requests_db: Dict[str, HITLRequest] = {}
dead_end_tasks_db: List[DeadEndTask] = []
missions_db: Dict[str, Mission] = {}
agents_db: Dict[str, Agent] = {}

# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.session_connections: Dict[str, Set[str]] = {}

    async def connect(self, websocket: WebSocket, client_id: str, session_id: Optional[str] = None):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        if session_id:
            if session_id not in self.session_connections:
                self.session_connections[session_id] = set()
            self.session_connections[session_id].add(client_id)
        logger.info(f"Client {client_id} connected to session {session_id}")

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            # Remove from session connections
            for session_id, clients in self.session_connections.items():
                if client_id in clients:
                    clients.remove(client_id)
        logger.info(f"Client {client_id} disconnected")

    async def send_personal_message(self, message: str, client_id: str):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_text(message)

    async def broadcast_to_session(self, message: str, session_id: str):
        if session_id in self.session_connections:
            for client_id in self.session_connections[session_id]:
                if client_id in self.active_connections:
                    await self.active_connections[client_id].send_text(message)

    async def broadcast(self, message: str):
        for client_id, connection in self.active_connections.items():
            await connection.send_text(message)

manager = ConnectionManager()

# Initialize sample data
async def initialize_sample_data():
    """Initialize sample agents and workflows for testing"""
    
    # Sample agents
    agents = [
        Agent(
            id="agent-1",
            name="Research Agent",
            role=AgentRole.RESEARCHER,
            capabilities=["web_search", "document_analysis", "data_extraction"]
        ),
        Agent(
            id="agent-2",
            name="Analysis Agent",
            role=AgentRole.ANALYST,
            capabilities=["data_analysis", "pattern_recognition", "report_generation"]
        ),
        Agent(
            id="agent-3",
            name="Execution Agent",
            role=AgentRole.EXECUTOR,
            capabilities=["task_execution", "api_calls", "file_operations"]
        )
    ]
    
    for agent in agents:
        agents_db[agent.id] = agent
    
    logger.info("Sample data initialized")

# API Endpoints

@app.get("/")
async def root():
    return {"message": "Jarvis AI Orchestrator Backend", "status": "online"}

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "redis": redis_client is not None
    }

# Mission endpoints
@app.post("/api/missions", response_model=Mission)
async def create_mission(mission: Mission):
    """Submit a new mission"""
    missions_db[mission.id] = mission
    
    # Create initial workflow
    workflow = Workflow(
        session_id=mission.session_id,
        name=f"Workflow for {mission.name}",
        nodes=[
            WorkflowNode(
                id="start",
                type="start",
                position={"x": 100, "y": 100},
                data={"label": "Mission Start", "mission_id": mission.id}
            )
        ],
        edges=[]
    )
    workflows_db[workflow.id] = workflow
    
    # Broadcast mission creation
    await manager.broadcast_to_session(
        json.dumps({
            "type": "mission_created",
            "data": mission.dict()
        }),
        mission.session_id
    )
    
    # Log mission creation
    log_entry = LogEntry(
        session_id=mission.session_id,
        level=LogLevel.INFO,
        message=f"Mission '{mission.name}' created",
        metadata={"mission_id": mission.id}
    )
    logs_db.append(log_entry)
    
    return mission

@app.get("/api/missions/{mission_id}", response_model=Mission)
async def get_mission(mission_id: str):
    """Get mission details"""
    if mission_id not in missions_db:
        raise HTTPException(status_code=404, detail="Mission not found")
    return missions_db[mission_id]

# Workflow endpoints
@app.get("/api/workflow/{session_id}", response_model=Workflow)
async def get_workflow(session_id: str):
    """Get current workflow state for a session"""
    for workflow in workflows_db.values():
        if workflow.session_id == session_id:
            return workflow
    raise HTTPException(status_code=404, detail="Workflow not found")

@app.post("/api/workflow/{session_id}/update")
async def update_workflow(session_id: str, nodes: List[WorkflowNode], edges: List[WorkflowEdge]):
    """Update workflow graph"""
    for workflow in workflows_db.values():
        if workflow.session_id == session_id:
            workflow.nodes = nodes
            workflow.edges = edges
            workflow.updated_at = datetime.now().isoformat()
            
            # Broadcast update
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "workflow_updated",
                    "data": workflow.dict()
                }),
                session_id
            )
            return {"status": "updated"}
    raise HTTPException(status_code=404, detail="Workflow not found")

# Logs endpoints
@app.get("/api/logs")
async def stream_logs(
    session_id: Optional[str] = Query(None),
    agent_id: Optional[str] = Query(None),
    level: Optional[LogLevel] = Query(None),
    limit: int = Query(100)
):
    """Stream logs with optional filters"""
    filtered_logs = logs_db
    
    if session_id:
        filtered_logs = [log for log in filtered_logs if log.session_id == session_id]
    if agent_id:
        filtered_logs = [log for log in filtered_logs if log.agent_id == agent_id]
    if level:
        filtered_logs = [log for log in filtered_logs if log.level == level]
    
    # Return latest logs
    filtered_logs = filtered_logs[-limit:]
    
    async def generate():
        for log in filtered_logs:
            yield f"data: {json.dumps(log.dict())}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")

@app.post("/api/logs")
async def add_log(log: LogEntry):
    """Add a new log entry"""
    logs_db.append(log)
    
    # Broadcast log to session
    await manager.broadcast_to_session(
        json.dumps({
            "type": "log_added",
            "data": log.dict()
        }),
        log.session_id
    )
    return {"status": "logged"}

# HITL (Human-in-the-Loop) endpoints
@app.get("/api/hitl/pending")
async def get_pending_hitl_requests(session_id: Optional[str] = Query(None)):
    """Get pending HITL requests"""
    requests = [r for r in hitl_requests_db.values() if r.status == "pending"]
    if session_id:
        requests = [r for r in requests if r.session_id == session_id]
    return requests

@app.post("/api/hitl/request", response_model=HITLRequest)
async def create_hitl_request(request: HITLRequest):
    """Create a new HITL request"""
    hitl_requests_db[request.id] = request
    
    # Broadcast HITL request
    await manager.broadcast_to_session(
        json.dumps({
            "type": "hitl_request",
            "data": request.dict()
        }),
        request.session_id
    )
    
    # Log HITL request
    log_entry = LogEntry(
        session_id=request.session_id,
        level=LogLevel.WARNING,
        message=f"HITL required: {request.prompt}",
        metadata={"hitl_id": request.id, "task_id": request.task_id}
    )
    logs_db.append(log_entry)
    
    return request

@app.post("/api/hitl/{request_id}/approve")
async def approve_hitl_request(request_id: str, response: Optional[Dict[str, Any]] = Body(None)):
    """Approve a HITL request"""
    if request_id not in hitl_requests_db:
        raise HTTPException(status_code=404, detail="HITL request not found")
    
    request = hitl_requests_db[request_id]
    request.status = "approved"
    request.response = response
    
    # Update workflow node status
    for workflow in workflows_db.values():
        if workflow.session_id == request.session_id:
            for node in workflow.nodes:
                if node.id == request.task_id:
                    node.status = TaskStatus.RUNNING
                    break
    
    # Broadcast approval
    await manager.broadcast_to_session(
        json.dumps({
            "type": "hitl_approved",
            "data": {"request_id": request_id, "task_id": request.task_id}
        }),
        request.session_id
    )
    
    # Log approval
    log_entry = LogEntry(
        session_id=request.session_id,
        level=LogLevel.INFO,
        message=f"HITL request approved for task {request.task_id}",
        metadata={"hitl_id": request_id}
    )
    logs_db.append(log_entry)
    
    return {"status": "approved"}

@app.post("/api/hitl/{request_id}/deny")
async def deny_hitl_request(request_id: str, reason: Optional[str] = Body(None)):
    """Deny a HITL request"""
    if request_id not in hitl_requests_db:
        raise HTTPException(status_code=404, detail="HITL request not found")
    
    request = hitl_requests_db[request_id]
    request.status = "denied"
    request.response = {"reason": reason}
    
    # Update workflow node status
    for workflow in workflows_db.values():
        if workflow.session_id == request.session_id:
            for node in workflow.nodes:
                if node.id == request.task_id:
                    node.status = TaskStatus.FAILED
                    break
    
    # Broadcast denial
    await manager.broadcast_to_session(
        json.dumps({
            "type": "hitl_denied",
            "data": {"request_id": request_id, "task_id": request.task_id, "reason": reason}
        }),
        request.session_id
    )
    
    # Log denial
    log_entry = LogEntry(
        session_id=request.session_id,
        level=LogLevel.WARNING,
        message=f"HITL request denied for task {request.task_id}: {reason}",
        metadata={"hitl_id": request_id}
    )
    logs_db.append(log_entry)
    
    return {"status": "denied"}

# Dead-end shelf endpoints
@app.get("/api/dead-ends")
async def get_dead_end_tasks(session_id: Optional[str] = Query(None)):
    """Get dead-end tasks"""
    tasks = dead_end_tasks_db
    if session_id:
        tasks = [t for t in tasks if t.session_id == session_id]
    return tasks

@app.post("/api/dead-ends", response_model=DeadEndTask)
async def add_dead_end_task(task: DeadEndTask):
    """Add a task to the dead-end shelf"""
    dead_end_tasks_db.append(task)
    
    # Update workflow node status
    for workflow in workflows_db.values():
        if workflow.session_id == task.session_id:
            for node in workflow.nodes:
                if node.id == task.task_id:
                    node.status = TaskStatus.DEAD_END
                    break
    
    # Broadcast dead-end task
    await manager.broadcast_to_session(
        json.dumps({
            "type": "dead_end_added",
            "data": task.dict()
        }),
        task.session_id
    )
    
    # Log dead-end
    log_entry = LogEntry(
        session_id=task.session_id,
        level=LogLevel.ERROR,
        message=f"Task {task.task_id} moved to dead-end shelf: {task.reason}",
        metadata={"task_id": task.task_id}
    )
    logs_db.append(log_entry)
    
    return task

@app.post("/api/dead-ends/{task_id}/retry")
async def retry_dead_end_task(task_id: str):
    """Retry a dead-end task"""
    for task in dead_end_tasks_db:
        if task.id == task_id:
            if not task.can_retry:
                raise HTTPException(status_code=400, detail="Task cannot be retried")
            
            # Remove from dead-end shelf
            dead_end_tasks_db.remove(task)
            
            # Update workflow node status
            for workflow in workflows_db.values():
                if workflow.session_id == task.session_id:
                    for node in workflow.nodes:
                        if node.id == task.task_id:
                            node.status = TaskStatus.PENDING
                            break
            
            # Broadcast retry
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "dead_end_retry",
                    "data": {"task_id": task_id}
                }),
                task.session_id
            )
            
            return {"status": "retrying"}
    
    raise HTTPException(status_code=404, detail="Dead-end task not found")

# Agent endpoints
@app.get("/api/agents")
async def get_agents():
    """Get all available agents"""
    return list(agents_db.values())

@app.get("/api/agents/{agent_id}")
async def get_agent(agent_id: str):
    """Get agent details"""
    if agent_id not in agents_db:
        raise HTTPException(status_code=404, detail="Agent not found")
    return agents_db[agent_id]

# WebSocket endpoint
@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str, session_id: Optional[str] = Query(None)):
    await manager.connect(websocket, client_id, session_id)
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # Handle different message types
            if message["type"] == "ping":
                await manager.send_personal_message(
                    json.dumps({"type": "pong", "timestamp": datetime.now().isoformat()}),
                    client_id
                )
            elif message["type"] == "subscribe":
                # Subscribe to a session
                new_session_id = message.get("session_id")
                if new_session_id:
                    if new_session_id not in manager.session_connections:
                        manager.session_connections[new_session_id] = set()
                    manager.session_connections[new_session_id].add(client_id)
            elif message["type"] == "task_progress":
                # Broadcast task progress to session
                await manager.broadcast_to_session(
                    json.dumps({
                        "type": "task_progress",
                        "data": message.get("data", {})
                    }),
                    session_id or message.get("session_id", "")
                )
            
    except WebSocketDisconnect:
        manager.disconnect(client_id)
        if session_id:
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "client_disconnected",
                    "client_id": client_id
                }),
                session_id
            )

# Simulated task execution (for testing)
async def simulate_workflow_execution(session_id: str):
    """Simulate workflow execution with progress updates"""
    await asyncio.sleep(1)
    
    # Add some nodes to the workflow
    for workflow in workflows_db.values():
        if workflow.session_id == session_id:
            # Add analysis node
            analysis_node = WorkflowNode(
                id="analysis-1",
                type="agent",
                position={"x": 300, "y": 100},
                data={"label": "Data Analysis", "agent": "Analysis Agent"},
                status=TaskStatus.RUNNING,
                reasoning="Analyzing input data for patterns"
            )
            workflow.nodes.append(analysis_node)
            workflow.edges.append(WorkflowEdge(
                source="start",
                target="analysis-1",
                animated=True
            ))
            
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "workflow_updated",
                    "data": workflow.dict()
                }),
                session_id
            )
            
            await asyncio.sleep(2)
            
            # Simulate HITL request
            hitl_request = HITLRequest(
                task_id="analysis-1",
                session_id=session_id,
                type="approval",
                prompt="Approve execution of external API call?",
                options=["Approve", "Deny"],
                context={"api": "OpenAI GPT-4", "purpose": "Advanced analysis"}
            )
            hitl_requests_db[hitl_request.id] = hitl_request
            
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "hitl_request",
                    "data": hitl_request.dict()
                }),
                session_id
            )
            
            # Update node status
            analysis_node.status = TaskStatus.HITL_REQUIRED
            
            await manager.broadcast_to_session(
                json.dumps({
                    "type": "workflow_updated",
                    "data": workflow.dict()
                }),
                session_id
            )

@app.post("/api/workflow/{session_id}/simulate")
async def trigger_simulation(session_id: str):
    """Trigger workflow simulation for testing"""
    asyncio.create_task(simulate_workflow_execution(session_id))
    return {"status": "simulation started"}

if __name__ == "__main__":
    uvicorn.run(
        "main:app",,
        host="0.0.0.0",,
        port=8000,,
        reload=True,,
        log_level="info"
    )
