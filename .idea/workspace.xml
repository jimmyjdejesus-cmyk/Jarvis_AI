<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="SELECTIVE" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="1ad3c874-3be4-4fa9-98fc-ac1ce9d0b9dd" name="Changes" comment="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;">
      <change afterPath="$PROJECT_DIR$/Modelfile.specialist" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/config.yaml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/database.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/notifications.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/admin.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/auth.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/chat.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/file_browser.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/sidebar.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/ui/token_tracker.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/Host App.url" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/app.py" beforeDir="false" afterPath="$PROJECT_DIR$/app.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/ollama_client.py" beforeDir="false" afterPath="$PROJECT_DIR$/ollama_client.py" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/rag_handler.py" beforeDir="false" afterPath="$PROJECT_DIR$/rag_handler.py" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_BRANCH_BY_REPOSITORY">
      <map>
        <entry key="$PROJECT_DIR$" value="Speculative_Decoding" />
      </map>
    </option>
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="ProjectColorInfo">{
  &quot;associatedIndex&quot;: 1
}</component>
  <component name="ProjectId" id="31K7o6s8UUv1yJA3rOUQ2aRo8gP" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent"><![CDATA[{
  "keyToString": {
    "ASKED_SHARE_PROJECT_CONFIGURATION_FILES": "true",
    "ModuleVcsDetector.initialDetectionPerformed": "true",
    "Python.app.executor": "Run",
    "Python.app_Version2.executor": "Run",
    "RunOnceActivity.ShowReadmeOnStart": "true",
    "RunOnceActivity.git.unshallow": "true",
    "SHARE_PROJECT_CONFIGURATION_FILES": "true",
    "git-widget-placeholder": "Speculative__Decoding__v1.0.1",
    "node.js.detected.package.eslint": "true",
    "node.js.detected.package.tslint": "true",
    "node.js.selected.package.eslint": "(autodetect)",
    "node.js.selected.package.tslint": "(autodetect)",
    "nodejs_package_manager_path": "npm",
    "settings.editor.selected.configurable": "advanced.settings",
    "vue.rearranger.settings.migration": "true"
  }
}]]></component>
  <component name="SharedIndexes">
    <attachedChunks>
      <set>
        <option value="bundled-js-predefined-d6986cc7102b-09060db00ec0-JavaScript-PY-251.26927.90" />
        <option value="bundled-python-sdk-41e8cd69c857-64d779b69b7a-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-251.26927.90" />
      </set>
    </attachedChunks>
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="1ad3c874-3be4-4fa9-98fc-ac1ce9d0b9dd" name="Changes" comment="" />
      <created>1755261081527</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1755261081527</updated>
      <workItem from="1755261082555" duration="12711000" />
      <workItem from="1755310604736" duration="24559000" />
    </task>
    <task id="LOCAL-00001" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; ###">
      <option name="closed" value="true" />
      <created>1755274156225</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1755274156225</updated>
    </task>
    <task id="LOCAL-00002" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; ###">
      <option name="closed" value="true" />
      <created>1755274295269</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1755274295269</updated>
    </task>
    <task id="LOCAL-00003" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; ###">
      <option name="closed" value="true" />
      <created>1755274536763</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1755274536763</updated>
    </task>
    <task id="LOCAL-00004" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;">
      <option name="closed" value="true" />
      <created>1755308073280</created>
      <option name="number" value="00004" />
      <option name="presentableId" value="LOCAL-00004" />
      <option name="project" value="LOCAL" />
      <updated>1755308073280</updated>
    </task>
    <task id="LOCAL-00005" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;">
      <option name="closed" value="true" />
      <created>1755308527232</created>
      <option name="number" value="00005" />
      <option name="presentableId" value="LOCAL-00005" />
      <option name="project" value="LOCAL" />
      <updated>1755308527232</updated>
    </task>
    <task id="LOCAL-00006" summary="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;">
      <option name="closed" value="true" />
      <created>1755355179881</created>
      <option name="number" value="00006" />
      <option name="presentableId" value="LOCAL-00006" />
      <option name="project" value="LOCAL" />
      <updated>1755355179881</updated>
    </task>
    <option name="localTasksCounter" value="7" />
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="VcsManagerConfiguration">
    <MESSAGE value="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; ###" />
    <MESSAGE value="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;" />
    <option name="LAST_COMMIT_MESSAGE" value="This is the base Version for Janus_Ai, a Llama 3 locally hosted NLP, I will be testing a few different LLama models but I am starting with Gemma3 12B. this model uses duck duck go and currently does not save chat history as it is hosted locally in the streamlit window. I do intend to create variations with the different models for different projects including mixing IOT devices into the work flow.&#10; &#10; ### Side note-&#10; I wish i could have chosen Jarvis_AI lol, maybe a various could be. &#10; &quot;&quot;&quot;&#10; &#10; Janus sounds funny, jarvis is  a little better.&#10;&quot;&quot;&quot;&#10; #Added the modular model baseline code&#10; &quot;&quot;&quot;&#10; in the streamlit UI, you can choose the model for the task you need done&#10;more flexibility will be added as I find the limits of the system.&#10;&#10;I note that the system is painfully slow, im going to try speculative decoding and see the different at runtime.&#10;&quot;&quot;&quot;" />
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/Janus_Ai$app_Version2.coverage" NAME="app_Version2 Coverage Results" MODIFIED="1755262531849" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
    <SUITE FILE_PATH="coverage/Janus_Ai$app.coverage" NAME="app Coverage Results" MODIFIED="1755262615271" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="false" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
  </component>
</project>